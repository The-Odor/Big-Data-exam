% Do not modify these
\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}



% -- Insert any custom LaTeX packages here --

% \package{natbib} % <-- Required for the Chicago citation style
% \package{apacite} % <-- Required for the APA citation style
% If you decide to use one of the styles above, remember to change the \bibliographystyle{} at the bottom of the document too!

\usepackage{listings} % <-- Required if you want to display program source code in your paper.
\usepackage{xcolor}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
    }
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\urlstyle{same}

% -- End of custom LaTeX packages --


% Fill in your title
\title{Exploring Bitcoin }

% Do not modify the author tag below, just let it be blank
\author{}

% Fill in assignment abstract
\begin{abstract}
In this assignment we parsed a dataset, in the form of XMLs, through a Hadoop- and Pig apache. We learned how to write MapReduce jobs and Pig scripts, and how effective it is on our dataset based on XML files from Bitcoin stack exchange. 

\end{abstract}


% Do not modify the following two lines
\lstset{style=mystyle}
\begin{document}
\include{cover}


% Insert data for the hand-in's cover page
\makecoverpage{
	master_of 		 = \par{Applied Computer Science},  % Use either: Applied Computer Science | Human-Computer Interaction
	assignment_title = \par{ Exploring Bitcoin} ,  % Title of your assignment
	course_code    	 = \par{MA120},  % Course code (ex. MA110)
	course_name      = \par{Big Data},  % Course name (ex. Systems Development)
	due_date		 = \par{18 Oktober},  % Due date
	student_name     = \par{Theodore Midtbø Alstad ; Howie Chen},  % Your name (or names, if group – separate names with ; semicolon)
	student_number   = \par{865317 ; 866354},  % Your student ID number (or numbers, if group – separate ID numbers with ; semicolon)
	group_size		 = 2, % Number of group members (used for the declaration text)
}


% Do not modify the following two lines
\flushbottom
\maketitle

\tableofcontents
\newpage
% --INTRODUCTION--
\section{Introduction}
We choose to work together because both of us have python background, therefor we choose python as main programming language. We explored Bitcoin as given dataset from \url{archive.org/download/stackexchange/bitcoin.stackexchange.com.7z}  through Apaches: Hadoop and Pig. 

% --FUNCTIOS %-- 
\section{Main functions}
The datasets contains only XML files, which it means values to different attributes have a lot of  ascii characters, punctiations, numbers and HTML tags. We also needed a function to parse the XML files to Hadoop and to create a mapper for the data.  Therefor we created three different main functions thats being reused through the project. : 
\subsection{CleanBody}

In cleanBody function it formats strings for mapper function. The function makes non-case sensitivity, removes ascii characters , HTML formatting, and treats anything saperated by blanked space or as separated words. Most of the words after separating/splitting will be counted as separate words, and this will effect the results of some tasks. For instance  the name "Jens-Petter" will be counted as two words; "Jens" and "Petter". The input for the function is a string body which will be formatted and it returns a list of formatted string.

\begin{lstlisting}[language=Python, caption=CleanBody function]
def cleanBody(body):
    body = body.lower()
    body = ascii(body)
    body = sub("<.+?>","",body)
    body = body.replace("/", " ")
    body = body.strip()

    for i in ignore_char:
        	body = body.replace(i, "")

    body = body.split(" ")

    return body
\end{lstlisting}
\subsection{Mapper Core}
mapper\_core is the core of the mapper function; it prints out the relevant data in a format parseable by Hadoop. It functions through three modes, as determined by the parameter mode: "single", "double", and "triple".

\begin{itemize}
  \item Single: Assumes input "words" is a list of words to print. Prints word in words as (word, 1). Ignores empty strings and spaces.
  \item Double: Assumes input "words" is two nested lists to print. Prints word, count in words as (word, count). Ignores empty strings and spaces.
  \item Triple: Assumes input "words" is three nested lists to print. Prints id, score, title in words as (id, score, title). does not ignore empty strings and spaces.
\end{itemize}

\begin{lstlisting}[language=Python, caption=mapper\_core function]
def mapper_core(words, mode="single"):
    if mode == "single":
        for word in words:
            if word not in ["", " "]:
              print("%s %s" %(word,1)) #Emit the word

    elif mode == "double":
        in1, in2 = words
        for word, count in zip(in1,in2):
            if word not in ["", " "]:
                print("%s %s" %(word,count)) #emit the words

    elif mode == "triple":
        in1, in2,in3  = words
        for id, score, title in zip(in1,in2,in3):
            print("%s %s %s" %(id,score, title)) #emit the words


\end{lstlisting}

\subsection{Xmlparser}
The chosen method to interpret the dataset is to parse to the mapper function. Although parsing an entire XML-file takes up significant memory, this method fits our dataset. It has been separated out as a function so it may be easily replaced by other methods more fit for large files. The input for this function is a XML-file and the output is a parsed XML-file 

\begin{lstlisting}[language=Python, caption=xmlparser function]
def xmlparser(infile):
    if not isinstance(infile, str):
        infile = infile.detach()
    mytree = ET.parse(infile)
    myroot = mytree.getroot()
    return myroot
\end{lstlisting}
% --TASK1--
\section{Task 1 Warmup}
%This part of the task is about get to know how hadoop- and pig apache works and how to parse XML  files throught python code. 
\subsection{a WordCount}
\textbf{Assumption}: Count the words in body of questions PostTypeID="1"  in the \textit{Posts.xml}  file. The result should be how many times a word occur in the body of questions.\\ \\
\textbf{Implementation}The will  \\ \\
\textbf{Notes/Reflection} bye bye  \\ \\

\lstinputlisting[firstline=500,lastline=510,title=1a\_output]{output1a.txt}

\subsection{Unique words}
\textbf{Assumption}: Write a MapReduce job where the result should be unique words in the titles PostTypeID="1" in the \textit{Posts.xml} File. \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=500,lastline=510,title=1b\_output]{output1b.txt}

\subsection{MoreThan10}
\textbf{Assumption}: Write a simple python code to check the title length in \textit{Posts.xml}. The result should output how many titles have more than 10 words.  \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=1,title=1c\_output]{output1c.txt}

\subsection{Stopwords}
\textbf{Assumption}: Write a simple python code based on task 1a to exclude \href{https://raw.githubusercontent.com/naimdjon/stopwords/master/stopwords.txt}{stopwords} from body of questions PostTypeID="1" in the \textit{Posts.xml}. The output should be text file without any stopwords. \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=500,lastline=509,title=1d\_output]{output1d.txt}


\subsection{Pig top 10}
\textbf{Assumption}: Write a pig script to select top 10 listed words after removing the stopwords from \textit{Posts.xml}. The output should print out top 10 listed words and the corresponding occurrence rate.\\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=1e\_output]{output1e.txt}

\subsection{Tags}
\textbf{Assumption}: Write a MapReduce job to create a dictionary over unique tags in  \textit{Posts.xml}. The result should print the unique tags.\\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=500,lastline=510,title=1f\_output]{output1f.txt}


% --TASK2--
\section{Task 2 Discover}
%This part of the task is about to looking through several 

\subsection{Counting }
\textbf{Assumption}: We chose to write a MapReduce job to count the total unique users there are in \textit{Users.xml}. The result will print out how many unique users there are.\\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=1,title=2a\_output]{output2a.txt}

\subsection{Unique users }
\textbf{Assumption}: Write a MapReduce job based on task 2a) to create a mapper  and a reducer functions in \textit{Users.xml}. The result should contain unique users in the dataset.  \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
 \lstinputlisting[firstline=500,lastline=510,title=2b\_output]{output2b.txt}

\subsection{Top miners }
\textbf{Assumption}:Write a MapReduce job to find top 10 users based on attribute Reputation="x" in \textit{Users.xml}. The result will print out top 10 users based on their reputation. \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=2c\_output]{output2c.txt}

\subsection{Top questions }
\textbf{Assumption}: Write a MapReduce job to find top 10 title questions PostTypeID="1"  based on attribute Score="x" in \textit{Posts.xml}.The result lists top 10 questions using id, question and the score.\\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=2d\_output]{output2d.txt}

\subsection{Favorite questions }
\textbf{Assumption}: Write a MapReduce job to find top 10 title questions PostTypeID="1"  based on attribute FavoriteCount="x" in \textit{Posts.xml}.The result lists top 10 questions like id, question and the score.\\ \\ \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=2e\_output]{output2e.txt}

\subsection{Average answers}
\textbf{Assumption}: \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=2f\_output]{output2f.txt}

\subsection{Countries }
\textbf{Assumption}: We chose to write a MapReduce job to discover users by countries in \textit{Users.xml}. The result lists different countries and corresponding users. \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=2g\_output]{output2g.txt}

\subsection{Names}
\textbf{Assumption}We chose to write a MapReduce job to find the most popular names in \textit{Users.xml}. The result lists top 10 common names and how many.  \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=21,title=2h\_output]{output2h.txt}


\subsection{Answers }
\textbf{Assumption}: Write a simple python code to find how many titles of questions PostTypeId="x" have at least one answers based on attribute AnswerCount in \textit{Users.xml}. The result prints out how many questions have been answered.  \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=2i\_output]{output2i.txt}

% --TASK3--
\section{Task 3 Numbers}

\subsection{Bigram }
\textbf{Assumption}: We chose to write a MapReduce job to find the most common pair of adjacent words in \textit{Posts.xml}.For instance, "big data" or "Fast car" are examples of bigram. The result print the most common bigram   \\\\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=3a\_output]{output3a.txt}

\subsection{Trigram }
\textbf{Assumption}: This task is based on 3a, to find three words that appear consecutively in \textit{Posts.xml}. The result print the most common trigram.  \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
\lstinputlisting[firstline=1,lastline=10,title=3b\_output]{output3b.txt}

\subsection{Combiner }
\textbf{Assumption}: Write a MapReduce job and add a combiner before  the data sent to the reducer. The result should be the same as a reducer, but the reducer recive a smaller volume of data.  \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection} Having a combiner in A MapReduce jobs saves us bandwidth and computational strain by decreasing the volume of data sent from the mapper.  What combiner means is to have a semi-reducer after the mapper before sending it to the reducer. 
\lstinputlisting[firstline=1,lastline=10,title=3c\_output]{output1a.txt}

\subsection{Useless}
\textbf{Assumption}:  We chose write a MapReduce job  to find how many times the word "useless" in \textit{Posts.xml} occurs in the body of questions PostTypeId="1". The result print how many times the word useless occurs.  \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}

% --TASK4--
\section{Task 4 Search engine}
\subsection{Title index}
\textbf{Assumption}: We chose to write MapReduce job to create index over titles, bodies and answers of questions in \textit{Posts.xml}. We are after having a simple index that lists publications in which a search term/s and occur/s. The result is a list of words and their index appearance in posts LOL \\ \\
\textbf{Implementation}  \\ \\
\textbf{Notes/Reflection}
%1792    1800
\lstinputlisting[firstline=1792,lastline=1800, title=4a\_output]{output4a.txt}



\section*{Conclusion}
% Do not modify this last lines
\end{document}